# ğŸš– NYC Taxi Data Pipeline â€“ Azure Data Factory & Databricks

## ğŸ“– Project Overview
This project demonstrates the design and implementation of an **end-to-end data engineering pipeline** for processing the **NYC Taxi dataset** using **Azure Data Factory (ADF)**, **Azure Databricks**, and **Azure Data Lake Storage (ADLS)**.

The pipeline automates data ingestion, transformation, and storage in an analytics-ready format. Business insights such as **vendor performance**, **payment trends**, and **trip distribution** were derived using Databricks.

---

## â“ Problem Statement
The NYC Taxi dataset contains millions of trip records with diverse attributes (vendor IDs, payment methods, fares, trip distances, etc.).  
Challenges include:
- Raw data inconsistencies â†’ not analytics-ready  
- Manual preparation â†’ time-consuming and not scalable  
- Need for automation â†’ to ensure **reliability, consistency, and efficiency**  

---

## ğŸ¯ Objectives
- Ingest raw trip data into **Azure Data Lake Storage (ADLS)**  
- Automate pipelines in **Azure Data Factory (ADF)** with parameterization  
- Apply filtering, aggregation, and schema enforcement using **Mapping Data Flows**  
- Store curated datasets in **Parquet format** for scalability & performance  
- Analyze processed data in **Databricks notebooks**  
- Automate execution using scheduled triggers  

---

## ğŸ—ï¸ System Architecture
**Components:**
- **Source**: NYC Taxi CSV (API endpoint)  
- **ADF Pipeline**: Copy Activity â†’ Mapping Data Flow â†’ Databricks Notebook  
- **Storage**: ADLS Gen2 with `raw/` and `processed/` layers  
- **Compute**: Azure Databricks  

---

## âš™ï¸ Implementation Details
1. **Configured Linked Services** â†’ ADLS, Databricks, Integration Runtime  
2. **Defined Datasets** â†’ Raw CSV & Processed Parquet  
3. **Copy Activity with Parameters** â†’ Ingest data from API to `raw/`  
4. **Mapping Data Flow** â†’ Transformations (filter, aggregate)  
5. **Databricks Analysis** â†’ Business insights on processed data  
6. **Automation** â†’ Weekly scheduled triggers  

---

## ğŸ“Š Results & Insights
âœ… Automated pipeline ingests & processes millions of trip records  
âœ… Processed data is stored in **Parquet format** for BI & analytics  
âœ… Key findings:
- Vendor 2 handled ~60% of rides  
- Credit card payments = ~70% of revenue  
- Short trips (<2 miles) dominate rides  
- Evening peak hours observed  

---

## ğŸ’° Cost & Service Comparison
- **Copy Activity** â†’ Low-cost, bulk ingestion  
- **Mapping Data Flow** â†’ Costlier, best for transformations  
- **Recommendation** â†’ Use Copy Activity for ingestion & Data Flows for transformation  

---

## â˜ï¸ AWS Equivalent
If implemented in AWS:
- **Storage** â†’ S3  
- **Ingestion** â†’ Glue, Lambda, or Data Pipeline  
- **Transformation** â†’ Glue ETL or EMR Spark  
- **Analysis** â†’ Databricks on AWS or EMR  
- **Triggering** â†’ EventBridge, Step Functions  

---

## ğŸ“‚ Repository Contents
- `README.md` â†’ Project documentation (this file)  
- `Parth_ADF_NYC_Taxi_Pipeline.docx` â†’ ğŸ“¥ **Download this file to view the complete detailed project report**  


 

 
